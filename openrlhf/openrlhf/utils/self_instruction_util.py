import random
random.seed(42)
import re
import string
def extract_questions(text :str)->list[str]:
    """
    test on questions content generated by llama 3.2 3B-instruct
    """
    
    # This regex matches everything from a pattern starting with "number + dot + space"
    # up to the next occurrence of the same format or the end of the text.
    # ?= indicates a positive lookahead, which does not consume characters.
    # $ represents the end of the string.

    pattern = r"\d+\.\s+(.*?)(?=\n\d+\.\s+|$)"

    # Use the DOTALL flag to make "." match newline characters as well
    questions = re.findall(pattern, text, flags=re.DOTALL)

    # Remove potential leading and trailing whitespace
    questions = [q.strip() for q in questions]

    return questions

def sample_machine_instructions(machine_instructions, similarities, n):
    """Sample n machine instructions from a list of machine instructions."""
    return random.sample(machine_instructions, min(n, len(machine_instructions)))

def encode_prompt(tokenizer, prompt_instructions: list[str], prompt_json: dict):
    """Encode multiple prompt instructions into a single string."""
    system_prompt = prompt_json["system"]
    user_prompt = prompt_json["user"]
    for idx, instruction in enumerate(prompt_instructions):
        instruction = re.sub(r"\s+", " ", instruction).strip().rstrip(":")
        user_prompt += f"{idx+1}. {instruction}\n"
    user_prompt += f"{len(prompt_instructions) + 1}."
    if tokenizer:
        item = []
        if system_prompt:
            item.append(
                {
                    "role": "system",
                    "content": system_prompt
                }
            )
        if user_prompt:
            item.append(
                {
                    "role": "user",
                    "content": user_prompt
                }
            )
        prompt = tokenizer.apply_chat_template(item, tokenize=False, add_generation_prompt=True)
    else:
        prompt = f'{system_prompt}\n{user_prompt}'
    return prompt


def find_word_in_string(w, s):
    return re.compile(r'\b({0})\b'.format(w), flags=re.IGNORECASE).search(s)

def post_process_response(response):
    if not response:
        return []

    raw_instructions = extract_questions(response)
    instructions = []
    for inst in raw_instructions:
        inst = re.sub(r"\s+", " ", inst).strip()
        inst = inst.strip().capitalize()
        if inst == "":
            continue
        # filter out too short or too long instructions
        if len(inst.split()) <= 3 or len(inst.split()) > 150:
            continue
        # filter based on keywords that are not suitable for language models.
        if any(find_word_in_string(word, inst) for word in ["image", "images", "graph", "graphs", "picture", "pictures", "file", "files", "map", "maps", "draw", "plot", "go to"]):
            continue
        # We found that the model tends to add "write a program" to some existing instructions, which lead to a lot of such instructions.
        # And it's a bit comfusing whether the model need to write a program or directly output the result. 
        # Here we filter them out.
        # Note this is not a comprehensive filtering for all programming instructions.
        if inst.startswith("Write a program"):
            continue
        # filter those starting with punctuation
        if inst[0] in string.punctuation:
            continue
        # filter those starting with non-english character
        if not inst[0].isascii():
            continue
        instructions.append(inst)
    return instructions